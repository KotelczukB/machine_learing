{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit"
  },
  "interpreter": {
   "hash": "8442f6ccc6f3e62483f82965cb95e8ac940d5a859ee503c448f2980695a39010"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stable-baselines3[extra]\n",
    "#!pip install numpy\n",
    "#!pip install tensorflow==2.3.0\n",
    "#!pip install gym\n",
    "#!pip install keras\n",
    "#!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.env.MillEnv_Tester import MillEnviroment\n",
    "from src.PlayController import Controller, AgentLoader\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from tensorflow import keras\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MillEnviroment(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = AgentLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras DQN\n",
    "dqn = loader.load_dqn_agent(\"./model/dqn_weights_512.h5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO Stable Baselines\n",
    "model_ppo = PPO.load(\"./model/nine_mens_mill_ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: 2, 1: 2, 2: 2, 3: 2, 4: 2, 5: 2, 6: 2, 7: 2, 8: 2, 9: 2, 10: 2, 11: 0, 12: 0, 13: 0, 14: 0, 15: 2, 16: 2, 17: 2, 18: 2, 19: 2, 20: 2, 21: 2, 22: 2, 23: 2}\n{0: 2, 1: 2, 2: 2, 3: 2, 4: 2, 5: 2, 6: 2, 7: 2, 8: 2, 9: 2, 10: 2, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 2, 17: 2, 18: 2, 19: 2, 20: 2, 21: 2, 22: 2, 23: 2}\n\nO------O------O\n| O----O----O | \n| | O--O--O | | \n| | |     | | | \nO-O-W\t  W-W-W\n| | |     | | | \n| | \u001b[33mW\u001b[0m--O--O | | \n| O----O----O | \nO------O------O\n(24, 15)\n"
     ]
    }
   ],
   "source": [
    "obs = env.step(615)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "616\nNone\n"
     ]
    }
   ],
   "source": [
    "# PPO\n",
    "action, _states = model_ppo.predict(obs[0])\n",
    "print(action)\n",
    "print(_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(22, 13)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "env.discret_mapper(563)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DQN\n",
    "predictions = model_dqn.predict(obs)"
   ]
  }
 ]
}